{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     19,
     29,
     38,
     101,
     128,
     138,
     164
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yash/Desktop/Decision-Flip-Experiments/plotter.py:4: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-4b53d1cef15b>\", line 6, in <module>\n",
      "    from plotter import *\n",
      "  File \"/home/yash/Desktop/Decision-Flip-Experiments/plotter.py\", line 1, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/matplotlib/pyplot.py\", line 69, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('Agg')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading CIFAR10\n",
      "\n",
      "Loading pre-Shuffled training data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/yash/Desktop/Decision-Flip-Experiments')\n",
    "from scipy.misc import imread\n",
    "import matplotlib.patches as mpatches\n",
    "from models import *\n",
    "from plotter import *\n",
    "from saveloader import *\n",
    "from fgsm_cifar import fgsm\n",
    "from fgsm_cifar_wrt_class_flipstop import fgsm_wrt_class\n",
    "from helper import *\n",
    "from helper import _to_categorical\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import numpy as np\n",
    "sd = 'shape_dict'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_data(X_test, X_train, sess, n, env, n_classes=10):\n",
    "    X_test_sub = X_test[:n]\n",
    "    X_train_sub = X_train[:n]\n",
    "    y_train_sub = sess.run(env.ybar, feed_dict={env.x: X_train_sub, env.training: False})\n",
    "    y_train_sub = _to_categorical(np.argmax(y_train_sub, axis=1), n_classes)\n",
    "    y_test_sub = sess.run(env.ybar, feed_dict={env.x: X_test_sub, env.training: False})\n",
    "    y_test_sub = _to_categorical(np.argmax(y_test_sub, axis=1), n_classes)\n",
    "\n",
    "    return X_test_sub, y_test_sub, X_train_sub, y_train_sub\n",
    "\n",
    "def plot_all_data_graph(method, epochs, n):\n",
    "    for from_cls in range(2):\n",
    "        for to_cls in range(n_classes):\n",
    "            if (from_cls != to_cls):\n",
    "                l2_test, l2_train, l2_random, l2_random_normal = restore_flip(method, epochs, n, from_cls, to_cls)\n",
    "                #There might be a prob. here! since lens are diff, solved it inside the func\n",
    "                plot_data_graph_without_random(l2_test, l2_train, l2_random, l2_random_normal, n, from_cls, to_cls)\n",
    "                plot_hists_without_random(l2_test, l2_train, n, from_cls, to_cls)\n",
    "\n",
    "def random_normal_func(X, n, save, lr, lrn):\n",
    "    X = X.reshape(-1, img_rows * img_cols * img_chas)\n",
    "    mean, std = np.mean(X, axis=0), np.std(X, axis=0)\n",
    "    randomX = np.zeros([n, X[0].size])\n",
    "    for i in range(X[0].size):\n",
    "        randomX[:, i] = np.random.normal(mean[i], std[i], n)\n",
    "    randomX = randomX.reshape(-1, img_rows, img_cols, img_chas)\n",
    "    X_random_normal = randomX\n",
    "    ans = sess.run(env.ybar, feed_dict={env.x: randomX, env.training: False})\n",
    "    y_random_normal = _to_categorical(np.argmax(ans, axis=1), n_classes)\n",
    "    X_random = np.random.rand(n, img_rows, img_cols, img_chas)\n",
    "    y_random = sess.run(env.ybar, feed_dict={env.x: X_random, env.training: False})\n",
    "    y_random = _to_categorical(np.argmax(y_random, axis=1), n_classes)\n",
    "\n",
    "    if (save):\n",
    "        save_as_txt(get_flip_path(lr), X_random)\n",
    "        save_as_txt(get_flip_path(lrn), X_random_normal)\n",
    "\n",
    "    return X_random, y_random, X_random_normal, y_random_normal\n",
    "\n",
    "def run_flip(method, epochs, n, cls=-1):\n",
    "    save_obj({},sd)\n",
    "    test_label = make_label(\"test\", method, epochs, n, False)\n",
    "    train_label = make_label(\"train\", method, epochs, n, False)\n",
    "    random_label = make_label(\"random\", method, epochs, n, False)\n",
    "    random_normal_label = make_label(\"random_normal\", method, epochs, n, False)\n",
    "    data_label_random, data_label_random_normal = make_label(\"_\", method, epochs, n, True)\n",
    "\n",
    "    X_test_sub, y_test_sub, X_train_sub, y_train_sub = make_data(X_test, X_train, sess, n, env)\n",
    "    X_random, y_random, X_random_normal, y_random_normal = random_normal_func(X_train, n, True,\n",
    "                                                                              data_label_random,\n",
    "                                                                              data_label_random_normal)\n",
    "    if (cls < -2 or cls > 9):\n",
    "        print(\"Invalid Params\")\n",
    "        return\n",
    "\n",
    "    if (method == 1):\n",
    "        X_flip_test = create_adv(X_test_sub, y_test_sub, test_label)\n",
    "        X_flip_train = create_adv(X_train_sub, y_train_sub, train_label)\n",
    "        X_flip_random = create_adv(X_random, y_random, random_label)\n",
    "        X_flip_random_normal = create_adv(X_random_normal, y_random_normal, random_normal_label)\n",
    "\n",
    "    if (method == 2):\n",
    "        X_flip_per_class_test = create_adv_wrt_class(X_test_sub, y_test_sub, test_label)\n",
    "        X_flip_per_class_train = create_adv_wrt_class(X_train_sub, y_train_sub, train_label)\n",
    "        X_flip_per_class_random = create_adv_wrt_class(X_random, y_random, random_label)\n",
    "        X_flip_per_class_random_normal = create_adv_wrt_class(X_random_normal, y_random_normal, random_normal_label)\n",
    "\n",
    "        _, X_flip_test = give_m2_ans(X_test_sub, X_flip_per_class_test, cls)\n",
    "        _, X_flip_train = give_m2_ans(X_train_sub, X_flip_per_class_train, cls)\n",
    "        _, X_flip_random = give_m2_ans(X_random, X_flip_per_class_random, cls)\n",
    "        _, X_flip_random_normal = give_m2_ans(X_random_normal, X_flip_per_class_random_normal, cls)\n",
    "\n",
    "    #     a = _predict(X_flip_test, env)\n",
    "    #     print(np.argmax(a,axis=1))\n",
    "\n",
    "    l2_test = find_l2(X_flip_test, X_test_sub)\n",
    "    l2_train = find_l2(X_flip_train, X_train_sub)\n",
    "    l2_random = find_l2(X_flip_random, X_random)\n",
    "    l2_random_normal = find_l2(X_flip_random_normal, X_random_normal)\n",
    "\n",
    "    return l2_test, l2_train, l2_random, l2_random_normal\n",
    "\n",
    "def restore_random_data(lr, lrn):\n",
    "    Xr = load_from_txt(get_flip_path(lr))\n",
    "    Xrn = load_from_txt(get_flip_path(lrn))\n",
    "    y_random_normal = sess.run(env.ybar, feed_dict={env.x: Xrn, env.training: False})\n",
    "    y_random_normal = _to_categorical(np.argmax(y_random_normal, axis=1), n_classes)\n",
    "    y_random = sess.run(env.ybar, feed_dict={env.x: Xr, env.training: False})\n",
    "    y_random = _to_categorical(np.argmax(y_random, axis=1), n_classes)\n",
    "\n",
    "    return Xr, y_random, Xrn, y_random_normal\n",
    "\n",
    "def restore_flip(method, epochs, n, from_cls=-1, to_cls=-1):\n",
    "    test_label = make_label(\"test\", method, epochs, n, False)\n",
    "    train_label = make_label(\"train\", method, epochs, n, False)\n",
    "    random_label = make_label(\"random\", method, epochs, n, False)\n",
    "    random_normal_label = make_label(\"random_normal\", method, epochs, n, False)\n",
    "    data_label_random, data_label_random_normal = make_label(\"_\", method, epochs, n, True)\n",
    "\n",
    "    X_test_sub, y_test_sub, X_train_sub, y_train_sub = make_data(X_test, X_train, sess, n, env)\n",
    "    X_random, y_random, X_random_normal, y_random_normal = restore_random_data(data_label_random,\n",
    "                                                                               data_label_random_normal)\n",
    "\n",
    "    if (method == 1):\n",
    "        X_flip_test = load_from_txt(get_flip_path(test_label))\n",
    "        X_flip_train = load_from_txt(get_flip_path(train_label))\n",
    "        X_flip_random = load_from_txt(get_flip_path(random_label))\n",
    "        X_flip_random_normal = load_from_txt(get_flip_path(random_normal_label))\n",
    "\n",
    "    if (method == 2):\n",
    "        X_flip_per_class_test = load_from_txt(get_flip_path(test_label))\n",
    "        X_flip_per_class_train = load_from_txt(get_flip_path(train_label))\n",
    "        X_flip_per_class_random = load_from_txt(get_flip_path(random_label))\n",
    "        X_flip_per_class_random_normal = load_from_txt(get_flip_path(random_normal_label))\n",
    "\n",
    "        if (from_cls != -1):\n",
    "            print('From Class ' + str(from_cls) + '\\n')\n",
    "            X_test_sub, y_test_sub, X_flip_per_class_test = get_class(X_test_sub, y_test_sub,\n",
    "                                                                      X_flip_per_class_test, from_cls)\n",
    "            X_train_sub, y_train_sub, X_flip_per_class_train = get_class(X_train_sub, y_train_sub,\n",
    "                                                                         X_flip_per_class_train, from_cls)\n",
    "            X_random, y_random, X_flip_per_class_random = get_class(X_random, y_random,\n",
    "                                                                    X_flip_per_class_random, from_cls)\n",
    "            X_random_normal, y_random_normal, X_flip_per_class_random_normal = get_class(\n",
    "                X_random_normal, y_random_normal, X_flip_per_class_random_normal, from_cls)\n",
    "            print('Test Data:' + str(y_test_sub.shape[0]))\n",
    "            print('Train Data: ' + str(y_train_sub.shape[0]))\n",
    "            print('Random Data: ' + str(y_random.shape[0]))\n",
    "            print('Random Normal Data: ' + str(y_random_normal.shape[0]))\n",
    "\n",
    "        _, X_flip_test = give_m2_ans(X_test_sub, X_flip_per_class_test, to_cls)\n",
    "        _, X_flip_train = give_m2_ans(X_train_sub, X_flip_per_class_train, to_cls)\n",
    "        _, X_flip_random = give_m2_ans(X_random, X_flip_per_class_random, to_cls)\n",
    "        _, X_flip_random_normal = give_m2_ans(X_random_normal, X_flip_per_class_random_normal, to_cls)\n",
    "\n",
    "    l2_test = find_l2(X_flip_test, X_test_sub)\n",
    "    l2_train = find_l2(X_flip_train, X_train_sub)\n",
    "    l2_random = find_l2(X_flip_random, X_random)\n",
    "    l2_random_normal = find_l2(X_flip_random_normal, X_random_normal)\n",
    "\n",
    "    return l2_test, l2_train, l2_random, l2_random_normal\n",
    "\n",
    "X_train, y_train, X_test, y_test, X_valid, y_valid = load_data(os)\n",
    "\n",
    "\n",
    "class Dummy:\n",
    "    pass\n",
    "\n",
    "env = Dummy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We need a scope since the inference graph will be reused later\n",
    "with tf.variable_scope('model'):\n",
    "    env.x = tf.placeholder(tf.float32, (None, img_rows, img_cols,\n",
    "                                        img_chas), name='x')\n",
    "    env.y = tf.placeholder(tf.float32, (None, n_classes), name='y')\n",
    "    env.training = tf.placeholder(bool, (), name='mode')\n",
    "\n",
    "    env.ybar, logits = model(env.x, logits=True,\n",
    "                             training=env.training)\n",
    "\n",
    "    z = tf.argmax(env.y, axis=1)\n",
    "    zbar = tf.argmax(env.ybar, axis=1)\n",
    "    env.count = tf.cast(tf.equal(z, zbar), tf.float32)\n",
    "    env.acc = tf.reduce_mean(env.count, name='acc')\n",
    "\n",
    "    xent = tf.nn.softmax_cross_entropy_with_logits(labels=env.y,\n",
    "                                                   logits=logits)\n",
    "    env.loss = tf.reduce_mean(xent, name='loss')\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    env.optim = tf.train.AdamOptimizer(beta1=0.9, beta2=0.999, epsilon=1e-08,).minimize(env.loss)\n",
    "\n",
    "with tf.variable_scope('model', reuse=True):\n",
    "    for i in range(n_classes):\n",
    "        if (i == 0):\n",
    "            env.x_adv_wrt_class = (fgsm_wrt_class(model, env.x, i, step_size=.05, bbox_semi_side=10))\n",
    "        else:\n",
    "            x = (fgsm_wrt_class(model, env.x, i, step_size=.05, bbox_semi_side=10))\n",
    "            env.x_adv_wrt_class = tf.concat([env.x_adv_wrt_class, x], axis=0)\n",
    "    env.x_adv, env.all_flipped = fgsm(model, env.x, step_size=.05, bbox_semi_side=10)  # epochs is redundant now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     4
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_model(label):\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess,  './models/cifar/' + label)\n",
    "    \n",
    "def restore_model(label):\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './models/cifar/' + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _evaluate(X_data, y_data, env):\n",
    "    print('\\nEvaluating')\n",
    "    n_sample = X_data.shape[0]\n",
    "    batch_size = 128\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    loss, acc = 0, 0\n",
    "    ns = 0\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        batch_loss, batch_count, batch_acc = sess.run(\n",
    "            [env.loss, env.count, env.acc],\n",
    "            feed_dict={env.x: X_data[start:end],\n",
    "                       env.y: y_data[start:end],\n",
    "                       env.training: False})\n",
    "        loss += batch_loss*batch_size\n",
    "        ns+=batch_size\n",
    "        acc += batch_acc*batch_size\n",
    "    loss /= ns\n",
    "    acc /= ns\n",
    "    print(' loss: {0:.4f} acc: {1:.4f}'.format(loss, acc))\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     15,
     37
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _predict(X_data, env):\n",
    "    print('\\nPredicting')\n",
    "    n_sample = X_data.shape[0]\n",
    "    batch_size = 128\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    yval = np.empty((X_data.shape[0], n_classes))\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        batch_y = sess.run(env.ybar, feed_dict={\n",
    "            env.x: X_data[start:end], env.training: False})\n",
    "        yval[start:end] = batch_y\n",
    "    return yval\n",
    "\n",
    "def train(label):\n",
    "    print('\\nTraining')\n",
    "    n_sample = X_train.shape[0]\n",
    "    batch_size = 128\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    n_epoch = 50\n",
    "    for epoch in range(n_epoch):\n",
    "        print('Epoch {0}/{1}'.format(epoch+1, n_epoch))\n",
    "        for ind in range(n_batch):\n",
    "            print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "            start = ind*batch_size\n",
    "            end = min(n_sample, start+batch_size)\n",
    "            sess.run(env.optim, feed_dict={env.x: X_train[start:end],\n",
    "                                           env.y: y_train[start:end],\n",
    "                                           env.training: True})\n",
    "        if(epoch%5 == 0):\n",
    "            model_label = label+ '{0}'.format(epoch)\n",
    "            print(\"saving model \" + model_label)\n",
    "            save_model(model_label)\n",
    "            \n",
    "    save_model(label)\n",
    "\n",
    "def train_again(X, y, epochs):\n",
    "    #Not making batches, do that if size > 128\n",
    "    for i in range(X.shape[0]):\n",
    "        for e in range(epochs):\n",
    "            sess.run(env.optim, feed_dict={env.x: [X[i]],\n",
    "                                           env.y: [y[i]],\n",
    "                                           env.training: True})\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_adv_wrt_class(X, Y, label = None):\n",
    "    print('\\nCrafting adversarial')\n",
    "    n_sample = X.shape[0]\n",
    "    pred = np.argmax(Y,axis=1)\n",
    "    batch_size = 1\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    n_epoch = 20\n",
    "    x_adv_shape = list(X.shape)[1:]\n",
    "    x_adv_shape = np.append(np.append(n_sample,n_classes),x_adv_shape)\n",
    "    X_adv = np.empty(x_adv_shape)\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        tmp = sess.run(env.x_adv_wrt_class, feed_dict={env.x: X[start:end],\n",
    "                                             env.y: Y[start:end],\n",
    "                                             env.training: False})\n",
    "        tmp[pred[start]] = X[start]\n",
    "        X_adv[start:end] = tmp\n",
    "    if(label != None):\n",
    "        print('\\nSaving adversarial')\n",
    "        os.makedirs('data', exist_ok=True)\n",
    "        save_as_txt(get_flip_path(label), X_adv)\n",
    "    return X_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_adv(X, Y, label):\n",
    "    print('\\nCrafting adversarial')\n",
    "    n_sample = X.shape[0]\n",
    "    batch_size = 1\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    n_epoch = 20\n",
    "    X_adv = np.empty_like(X)\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        tmp, all_flipped = sess.run([env.x_adv, env.all_flipped], feed_dict={env.x: X[start:end],\n",
    "                                             env.y: Y[start:end],\n",
    "                                             env.training: False})\n",
    "        X_adv[start:end] = tmp\n",
    "    print('\\nSaving adversarial')\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    save_as_txt(get_flip_path(label), X_adv)\n",
    "    return X_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/cifar/cifar_with_cnn200\n",
      "\n",
      "Crafting adversarial\n",
      " batch 50/50\n",
      "Saving adversarial\n"
     ]
    }
   ],
   "source": [
    "method = 2\n",
    "n = 1000\n",
    "epochs = 200\n",
    "label=\"cifar_with_cnn\"\n",
    "cls = -1\n",
    "\n",
    "# train(label)\n",
    "restore_model(label + str(epochs))\n",
    "\n",
    "X = X_train[:50]\n",
    "y = y_train[:50]\n",
    "\n",
    "lbl = \"temp_exp_flipstop\"\n",
    "Xflip = create_adv_wrt_class(X,y,lbl)\n",
    "Xf = load_from_txt(get_flip_path(lbl))w\n",
    "# print(Xflip == Xf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      "[8 1 0 9 8 8 8 8 8 9]\n",
      "7\n",
      "\n",
      "Predicting\n",
      "[0 1 2 2 4 5 6 4 8 4]\n",
      "3\n",
      "\n",
      "Predicting\n",
      "[6 6 6 6 4 5 6 7 6 6]\n",
      "6\n",
      "\n",
      "Predicting\n",
      "[7 7 2 3 4 7 6 7 4 9]\n",
      "4\n",
      "\n",
      "Predicting\n",
      "[4 4 2 3 4 6 6 7 4 4]\n",
      "5\n",
      "\n",
      "Predicting\n",
      "[0 1 2 2 2 5 2 7 8 9]\n",
      "3\n",
      "\n",
      "Predicting\n",
      "[0 1 2 3 4 1 6 1 0 9]\n",
      "3\n",
      "\n",
      "Predicting\n",
      "[4 1 3 3 4 5 3 4 4 4]\n",
      "6\n",
      "\n",
      "Predicting\n",
      "[3 4 4 3 4 5 6 7 3 3]\n",
      "5\n",
      "\n",
      "Predicting\n",
      "[3 1 2 6 4 3 6 3 8 9]\n",
      "4\n",
      "\n",
      "Predicting\n",
      "[0 0 2 3 4 5 0 7 0 0]\n",
      "4\n",
      "\n",
      "Predicting\n",
      "[0 1 2 2 2 2 2 2 8 9]\n",
      "5\n",
      "\n",
      "Predicting\n",
      "[3 2 2 3 4 5 6 7 3 9]\n",
      "3\n",
      "\n",
      "Predicting\n",
      "[0 1 0 3 8 8 8 7 8 9]\n",
      "4\n",
      "\n",
      "Predicting\n",
      "[0 1 2 3 2 5 6 5 2 6]\n",
      "4\n",
      "\n",
      "Predicting\n",
      "[8 1 4 3 4 5 4 8 8 9]\n",
      "4\n",
      "\n",
      "Predicting\n",
      "[0 1 0 3 0 5 3 3 8 0]\n",
      "5\n",
      "\n",
      "Predicting\n",
      "[0 7 2 3 4 5 6 7 3 3]\n",
      "3\n",
      "\n",
      "Predicting\n",
      "[4 1 4 4 4 5 4 4 8 9]\n",
      "5\n",
      "\n",
      "Predicting\n",
      "[0 9 2 5 4 5 6 9 8 9]\n",
      "3\n",
      "\n",
      "Predicting\n",
      "[0 1 5 3 5 5 5 7 8 9]\n",
      "3\n",
      "\n",
      "Predicting\n",
      "[4 4 2 3 4 3 6 4 4 9]\n",
      "5\n",
      "\n",
      "Predicting\n",
      "[6 1 6 6 6 6 6 6 8 6]\n",
      "7\n",
      "\n",
      "Predicting\n",
      "[0 9 2 9 9 9 6 5 1 9]\n",
      "6\n",
      "\n",
      "Predicting\n",
      "[3 0 3 3 4 5 6 7 3 3]\n",
      "5\n",
      "\n",
      "Predicting\n",
      "[0 1 9 9 9 8 9 9 8 9]\n",
      "6\n",
      "\n",
      "Predicting\n",
      "[5 1 4 5 4 5 6 7 8 9]\n",
      "3\n",
      "\n",
      "Predicting\n",
      "[0 1 2 3 4 7 0 7 8 9]\n",
      "2\n",
      "\n",
      "Predicting\n",
      "[0 1 0 4 4 0 6 0 0 9]\n",
      "5\n",
      "\n",
      "Predicting\n",
      "[5 5 5 5 5 5 5 7 5 5]\n",
      "8\n",
      "\n",
      "Predicting\n",
      "[0 1 2 3 3 7 6 7 0 9]\n",
      "3\n",
      "\n",
      "Predicting\n",
      "[0 1 2 3 4 5 6 7 3 3]\n",
      "2\n",
      "\n",
      "Predicting\n",
      "[4 6 2 4 4 7 6 7 4 4]\n",
      "6\n",
      "\n",
      "Predicting\n",
      "[0 1 4 3 4 5 6 7 4 1]\n",
      "3\n",
      "\n",
      "Predicting\n",
      "[0 8 2 6 0 5 6 0 8 8]\n",
      "5\n",
      "\n",
      "Predicting\n",
      "[0 1 5 3 1 5 6 7 1 9]\n",
      "3\n",
      "\n",
      "Predicting\n",
      "[0 5 2 3 4 5 5 7 8 9]\n",
      "2\n",
      "\n",
      "Predicting\n",
      "[0 8 2 3 0 5 6 3 8 8]\n",
      "4\n",
      "\n",
      "Predicting\n",
      "[0 0 2 3 4 5 6 7 0 3]\n",
      "3\n",
      "\n",
      "Predicting\n",
      "[6 6 2 6 4 5 6 7 6 6]\n",
      "5\n",
      "\n",
      "Predicting\n",
      "[4 4 4 4 4 4 6 7 4 4]\n",
      "7\n",
      "\n",
      "Predicting\n",
      "[0 4 2 2 4 5 6 7 8 4]\n",
      "3\n",
      "\n",
      "Predicting\n",
      "[5 1 2 3 5 5 5 7 5 9]\n",
      "4\n",
      "\n",
      "Predicting\n",
      "[0 0 2 3 4 5 3 7 8 9]\n",
      "2\n",
      "\n",
      "Predicting\n",
      "[5 5 2 5 4 5 5 7 5 2]\n",
      "6\n",
      "\n",
      "Predicting\n",
      "[0 9 2 4 4 3 6 4 8 9]\n",
      "4\n",
      "\n",
      "Predicting\n",
      "[1 1 2 5 4 5 6 7 1 1]\n",
      "4\n",
      "\n",
      "Predicting\n",
      "[3 3 2 2 4 3 3 3 3 3]\n",
      "8\n",
      "\n",
      "Predicting\n",
      "[0 0 0 3 4 3 4 7 0 0]\n",
      "6\n",
      "\n",
      "Predicting\n",
      "[0 1 2 3 4 5 5 7 5 9]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(Xf)):\n",
    "    pred = _predict(Xf[i],env)\n",
    "    a = (np.argmax(pred, axis = 1))\n",
    "    print(a)\n",
    "    c = (np.count_nonzero(a-[0,1,2,3,4,5,6,7,8,9]))\n",
    "    print('No.of multiple hits: ' + str(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lbl = \"temp_exp_flipstop200e\"\n",
    "\n",
    "save_as_txt(get_flip_path(lbl), Xflip)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

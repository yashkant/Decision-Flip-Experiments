{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     23,
     27,
     33,
     40,
     45,
     60,
     70,
     71,
     73,
     78,
     81,
     84,
     122,
     129
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/yash/Desktop/Decision-Flip-Experiments')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn import ModeKeys, Estimator\n",
    "import _pickle as pickle\n",
    "from scipy.misc import imread\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from fgsm_cifar import fgsm\n",
    "from fgsm_cifar_wrt_class import fgsm_wrt_class\n",
    "import sys  \n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "img_rows = 32\n",
    "img_cols = 32\n",
    "img_chas = 3\n",
    "input_shape = (img_rows, img_cols, img_chas)\n",
    "n_classes = 10\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open('data/misc/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('data/misc/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "sd = 'shape_dict'\n",
    "\n",
    "def save_as_txt(label,ar):\n",
    "    d=load_obj(sd)\n",
    "    d[label] = ar.shape\n",
    "    save_obj(d,sd)\n",
    "    X = ar.reshape((ar.shape[0],-1))\n",
    "    np.savetxt(label , X)\n",
    "\n",
    "def load_from_txt(label):\n",
    "    d=load_obj(sd)\n",
    "    X= np.loadtxt(label)\n",
    "    return X.reshape(d[label])\n",
    "\n",
    "def load_CIFAR10(ROOT):\n",
    "  \"\"\" load all of cifar \"\"\"\n",
    "  xs = []\n",
    "  ys = []\n",
    "  for b in range(1,6):\n",
    "    f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "    X, Y = load_CIFAR_batch(f)\n",
    "    xs.append(X)\n",
    "    ys.append(Y)    \n",
    "  Xtr = np.concatenate(xs)\n",
    "  Ytr = np.concatenate(ys)\n",
    "  del X, Y\n",
    "  Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "  return Xtr, Ytr, Xte, Yte\n",
    "\n",
    "def load_CIFAR_batch(filename):\n",
    "  \"\"\" load single batch of cifar \"\"\"\n",
    "  with open(filename, 'rb') as f:\n",
    "    datadict = pickle.load(f,encoding='latin1')\n",
    "    X = datadict['data']\n",
    "    Y = datadict['labels']\n",
    "    X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "    Y = np.array(Y)\n",
    "    return X, Y\n",
    "\n",
    "def make_label(i,m,e,n,r):\n",
    "    if(r == False):\n",
    "        return i + \"_m\" + str(m) + \"_e\" + str(e) + \"_n\" + str(n)\n",
    "    else:\n",
    "        base = i + \"_m\" + str(m) + \"_e\" + str(e) + \"_n\" + str(n) + \"_r\"\n",
    "        lrn = base + \"normal\"\n",
    "        return base, lrn\n",
    "\n",
    "def get_flip_path(l):\n",
    "    return 'data/cifar/' + l+ '.txt'\n",
    "\n",
    "def get_misc_path(l):\n",
    "    return 'data/misc/' + l+ '.txt'\n",
    "\n",
    "def random_normal_func(X, n, save, lr, lrn):\n",
    "    X=X.reshape(-1,img_rows*img_cols*img_chas)\n",
    "    mean, std = np.mean(X, axis=0), np.std(X,axis=0)\n",
    "    randomX = np.zeros([n,X[0].size])\n",
    "    for i in range(X[0].size):\n",
    "        randomX[:,i] = np.random.normal(mean[i],std[i],n)\n",
    "    randomX = randomX.reshape(-1,img_rows,img_cols,img_chas)\n",
    "    X_random_normal = randomX\n",
    "    ans = sess.run(env.ybar, feed_dict={env.x: randomX,env.training: False})\n",
    "    y_random_normal = _to_categorical(np.argmax(ans,axis=1), n_classes)\n",
    "    X_random = np.random.rand(n,img_rows,img_cols,img_chas)\n",
    "    y_random = sess.run(env.ybar, feed_dict={env.x: X_random,env.training: False})\n",
    "    y_random = _to_categorical(np.argmax(y_random, axis=1), n_classes)\n",
    "    \n",
    "    if(save):\n",
    "        save_as_txt(get_flip_path(lr),X_random)\n",
    "        save_as_txt(get_flip_path(lrn),X_random_normal)\n",
    "    \n",
    "    return X_random, y_random, X_random_normal, y_random_normal  \n",
    "\n",
    "def make_data():\n",
    "    y_train_sub = _predict(X_train,env)\n",
    "    y_train_sub = _to_categorical(np.argmax(y_train, axis=1), n_classes)\n",
    "    y_test_sub = _predict(X_test,env)\n",
    "    y_test_sub = _to_categorical(np.argmax(y_test, axis=1), n_classes)\n",
    "    \n",
    "    return X_test, y_test_sub, X_train, y_train_sub\n",
    "\n",
    "def run_flip(method, epochs):\n",
    "    save_obj({},sd)\n",
    "    #n is len here!\n",
    "    X_test, y_test, X_train, y_train = make_data()\n",
    "    \n",
    "    test_label = make_label(\"test\", method, epochs, len(X_train), False)\n",
    "    train_label = make_label(\"train\", method, epochs,len(X_test), False)\n",
    "    \n",
    "    X_flip_per_class_test = create_flip_wrt_class(X_test, y_test, test_label)\n",
    "    X_flip_per_class_train = create_flip_wrt_class(X_train, y_train, train_label)\n",
    "    \n",
    "\n",
    "def restore_flip(method, epochs):\n",
    "    test_label = make_label(\"test\", method, epochs,len(X_train), False)\n",
    "    train_label = make_label(\"train\", method, epochs,len(X_train), False)\n",
    "\n",
    "    X_flip_per_class_test = load_from_txt(get_flip_path(test_label))\n",
    "    X_flip_per_class_train = load_from_txt(get_flip_path(train_label))\n",
    "\n",
    "def _to_categorical(x, n_classes):\n",
    "    x = np.array(x, dtype=int).ravel()\n",
    "    n = x.shape[0]\n",
    "    ret = np.zeros((n, n_classes))\n",
    "    ret[np.arange(n), x] = 1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('\\nLoading CIFAR10')\n",
    "ab=sys.getdefaultencoding()\n",
    "print(ab)\n",
    "cifar10_dir = 'cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "\n",
    "X_train = X_train.reshape(-1, img_rows, img_cols, img_chas)\n",
    "X_test = X_test.reshape(-1, img_rows, img_cols, img_chas)\n",
    "\n",
    "y_train = _to_categorical(y_train, n_classes)\n",
    "y_test = _to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('\\nLoading pre-Shuffled training data')\n",
    "ind = np.loadtxt(get_misc_path('ind'), dtype = int)\n",
    "X_train, y_train = X_train[ind], y_train[ind]\n",
    "\n",
    "class Dummy:\n",
    "    pass\n",
    "env = Dummy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model(x, logits=False, training=False):\n",
    "    conv0 = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3],\n",
    "                             padding='same', name='conv0',\n",
    "                             activation=tf.nn.relu)\n",
    "    \n",
    "    pool0 = tf.layers.max_pooling2d(conv0, pool_size=[2, 2],\n",
    "                                    strides=2, name='pool0')\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(pool0, filters=64,\n",
    "                             kernel_size=[3, 3], padding='same',\n",
    "                             name='conv1', activation=tf.nn.relu)\n",
    "   \n",
    " \n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(conv1, pool_size=[2, 2],\n",
    "                                    strides=2, name='pool1')\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(pool1, filters=128,\n",
    "                             kernel_size=[1,1], padding='same',\n",
    "                             name='conv2', activation=tf.nn.relu)\n",
    "    \n",
    "\n",
    "    \n",
    "    flat = tf.reshape(conv2, [-1, 8*8*128], name='flatten')\n",
    "    \n",
    "    dense1 = tf.layers.dense(flat, units= 1024, activation=tf.nn.relu,\n",
    "                            name='dense1')\n",
    "    \n",
    "    dense2 = tf.layers.dense(dense1, units=128, activation=tf.nn.relu,\n",
    "                            name='dense2')\n",
    "    logits_ = tf.layers.dense(dense2, units=10, name='logits') #removed dropout\n",
    "    \n",
    "    y = tf.nn.softmax(logits_, name='ybar')\n",
    "    \n",
    "    if logits:\n",
    "        return y, logits_\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We need a scope since the inference graph will be reused later\n",
    "with tf.variable_scope('model'):\n",
    "    env.x = tf.placeholder(tf.float32, (None, img_rows, img_cols,\n",
    "                                        img_chas), name='x')\n",
    "    env.y = tf.placeholder(tf.float32, (None, n_classes), name='y')\n",
    "    env.training = tf.placeholder(bool, (), name='mode')\n",
    "\n",
    "    env.ybar, logits = model(env.x, logits=True,\n",
    "                             training=env.training)\n",
    "\n",
    "    z = tf.argmax(env.y, axis=1)\n",
    "    zbar = tf.argmax(env.ybar, axis=1)\n",
    "    env.count = tf.cast(tf.equal(z, zbar), tf.float32)\n",
    "    env.acc = tf.reduce_mean(env.count, name='acc')\n",
    "\n",
    "    xent = tf.nn.softmax_cross_entropy_with_logits(labels=env.y,\n",
    "                                                   logits=logits)\n",
    "    env.loss = tf.reduce_mean(xent, name='loss')\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    env.optim = tf.train.AdamOptimizer(beta1=0.9, beta2=0.999, epsilon=1e-08,).minimize(env.loss) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('model', reuse=True):\n",
    "    for i in range(n_classes):\n",
    "        if(i==0):\n",
    "            env.x_adv_wrt_class = (fgsm_wrt_class(model, env.x, i, step_size=.5, bbox_semi_side=10))\n",
    "        else:\n",
    "            x = (fgsm_wrt_class(model, env.x, i, step_size=.05, bbox_semi_side=10))\n",
    "            env.x_adv_wrt_class = tf.concat([env.x_adv_wrt_class, x],axis=0)\n",
    "    env.x_adv, env.all_flipped = fgsm(model, env.x, step_size=.05, bbox_semi_side=10) #epochs is redundant now!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     4
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_model(label):\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess,  './models/cifar/' + label)\n",
    "    \n",
    "def restore_model(label):\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './models/cifar/' + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _evaluate(X_data, y_data, env):\n",
    "    print('\\nEvaluating')\n",
    "    n_sample = X_data.shape[0]\n",
    "    batch_size = 128\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    loss, acc = 0, 0\n",
    "    ns = 0\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        batch_loss, batch_count, batch_acc = sess.run(\n",
    "            [env.loss, env.count, env.acc],\n",
    "            feed_dict={env.x: X_data[start:end],\n",
    "                       env.y: y_data[start:end],\n",
    "                       env.training: False})\n",
    "        loss += batch_loss*batch_size\n",
    "        ns+=batch_size\n",
    "        acc += batch_acc*batch_size\n",
    "    loss /= ns\n",
    "    acc /= ns\n",
    "    print(' loss: {0:.4f} acc: {1:.4f}'.format(loss, acc))\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     15,
     37
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _predict(X_data, env):\n",
    "    print('\\nPredicting')\n",
    "    n_sample = X_data.shape[0]\n",
    "    batch_size = 128\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    yval = np.empty((X_data.shape[0], n_classes))\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        batch_y = sess.run(env.ybar, feed_dict={\n",
    "            env.x: X_data[start:end], env.training: False})\n",
    "        yval[start:end] = batch_y\n",
    "    return yval\n",
    "\n",
    "def train(label):\n",
    "    print('\\nTraining')\n",
    "    n_sample = X_train.shape[0]\n",
    "    batch_size = 128\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    n_epoch = 50\n",
    "    for epoch in range(n_epoch):\n",
    "        print('Epoch {0}/{1}'.format(epoch+1, n_epoch))\n",
    "        for ind in range(n_batch):\n",
    "            print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "            start = ind*batch_size\n",
    "            end = min(n_sample, start+batch_size)\n",
    "            sess.run(env.optim, feed_dict={env.x: X_train[start:end],\n",
    "                                           env.y: y_train[start:end],\n",
    "                                           env.training: True})\n",
    "        if(epoch%5 == 0):\n",
    "            model_label = label+ '{0}'.format(epoch)\n",
    "            print(\"saving model \" + model_label)\n",
    "            save_model(model_label)\n",
    "            \n",
    "    save_model(label)\n",
    "\n",
    "def train_again(X, y, epochs):\n",
    "    #Not making batches, do that if size > 128\n",
    "    for i in range(X.shape[0]):\n",
    "        for e in range(epochs):\n",
    "            sess.run(env.optim, feed_dict={env.x: [X[i]],\n",
    "                                           env.y: [y[i]],\n",
    "                                           env.training: True})\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_flip_wrt_class(X, Y, label):\n",
    "    print('\\nCrafting Flipped')\n",
    "    n_sample = X.shape[0]\n",
    "    pred = np.argmax(Y,axis=1)\n",
    "    batch_size = 1\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    x_adv_shape = list(X.shape)[1:]\n",
    "    x_adv_shape = np.append(np.append(n_sample,n_classes),x_adv_shape)\n",
    "    X_adv = np.empty(x_adv_shape)\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        tmp = sess.run(env.x_adv_wrt_class, feed_dict={env.x: X[start:end],\n",
    "                                             env.y: Y[start:end],\n",
    "                                             env.training: False})\n",
    "        tmp[pred[start]] = X[start]\n",
    "        X_adv[start:end] = tmp\n",
    "    print('\\nSaving Flipped')\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    save_as_txt(get_flip_path(label), X_adv)\n",
    "    return X_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "method = 2\n",
    "epochs = 200\n",
    "label=\"cifar_with_cnn\"\n",
    "cls = -1\n",
    "\n",
    "X_test = X_test[2100:2120]\n",
    "y_test = y_test[2100:2120]\n",
    "\n",
    "restore_model(label + str(epochs))\n",
    "run_flip(method,epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

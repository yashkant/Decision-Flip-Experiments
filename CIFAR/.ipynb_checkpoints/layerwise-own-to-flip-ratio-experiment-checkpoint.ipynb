{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "code_folding": [
     17,
     39,
     59,
     89,
     94,
     99,
     108,
     114,
     143,
     147,
     162,
     171,
     177,
     184,
     202
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.chdir('/home/yash/Desktop/Decision-Flip-Experiments')\n",
    "from scipy.misc import imread\n",
    "import matplotlib.patches as mpatches\n",
    "from models import *\n",
    "from plotter import *\n",
    "from saveloader import *\n",
    "from fgsm_cifar import fgsm\n",
    "from fgsm_cifar_wrt_class import fgsm_wrt_class\n",
    "from helper import *\n",
    "from helper import _to_categorical\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import numpy as np\n",
    "sd = 'shape_dict'\n",
    "\n",
    "\n",
    "def plot_all_data_graph(method,epochs,n,lyr):\n",
    "    for from_cls in range(2):\n",
    "        for to_cls in range(n_classes):\n",
    "            if(from_cls != to_cls):\n",
    "                l2_test, l2_train = restore_flip(method,epochs,n,from_cls,to_cls,lyr)\n",
    "                #There might be a prob. here! since lens are diff, solved it inside the func\n",
    "                plot_data_graph_without_random(l2_test, l2_train, n,from_cls,to_cls,lyr)\n",
    "                plot_hists_without_random(l2_test, l2_train, n,from_cls,to_cls,lyr)\n",
    "                \n",
    "\n",
    "\n",
    "def make_data(n):\n",
    "    X_test_sub = X_test[:n]\n",
    "    X_train_sub = X_train[:n]\n",
    "    y_train_sub = sess.run(env.ybar, feed_dict={env.x: X_train_sub,env.training: False})\n",
    "    y_train_sub = _to_categorical(np.argmax(y_train_sub, axis=1), n_classes)\n",
    "    y_test_sub = sess.run(env.ybar, feed_dict={env.x:X_test_sub ,env.training: False})\n",
    "    y_test_sub = _to_categorical(np.argmax(y_test_sub, axis=1), n_classes)\n",
    "    \n",
    "    return X_test_sub, y_test_sub, X_train_sub, y_train_sub\n",
    "\n",
    "\n",
    "def random_normal_func(X, n, save, lr, lrn):\n",
    "    X=X.reshape(-1,img_rows*img_cols*img_chas)\n",
    "    mean, std = np.mean(X, axis=0), np.std(X,axis=0)\n",
    "    randomX = np.zeros([n,X[0].size])\n",
    "    for i in range(X[0].size):\n",
    "        randomX[:,i] = np.random.normal(mean[i],std[i],n)\n",
    "    randomX = randomX.reshape(-1,img_rows,img_cols,img_chas)\n",
    "    X_random_normal = randomX\n",
    "    ans = sess.run(env.ybar, feed_dict={env.x: randomX,env.training: False})\n",
    "    y_random_normal = _to_categorical(np.argmax(ans,axis=1), n_classes)\n",
    "    X_random = np.random.rand(n,img_rows,img_cols,img_chas)\n",
    "    y_random = sess.run(env.ybar, feed_dict={env.x: X_random,env.training: False})\n",
    "    y_random = _to_categorical(np.argmax(y_random, axis=1), n_classes)\n",
    "    \n",
    "    if(save):\n",
    "        save_as_txt(get_flip_path(lr),X_random)\n",
    "        save_as_txt(get_flip_path(lrn),X_random_normal)\n",
    "    \n",
    "    return X_random, y_random, X_random_normal, y_random_normal  \n",
    "\n",
    "def run_flip(method, epochs, n,from_cls=-1, to_cls = -1, layer= -1):\n",
    "    save_obj({},sd)\n",
    "    test_label = make_label(\"test\", method, epochs,n, False)\n",
    "    train_label = make_label(\"train\", method, epochs,n, False)\n",
    "    random_label = make_label(\"random\", method, epochs,n, False)\n",
    "    random_normal_label = make_label(\"random_normal\", method, epochs,n, False)\n",
    "#     data_label_random, data_label_random_normal = make_label(\"_\", method, epochs,n, True)\n",
    "    \n",
    "    X_test_sub, y_test_sub, X_train_sub, y_train_sub = make_data(n)\n",
    "#     X_random, y_random, X_random_normal, y_random_normal = restore_random_data(data_label_random, data_label_random_normal)\n",
    "    \n",
    "    if(method==2):\n",
    "        X_flip_per_class_test = create_adv_wrt_class(X_test_sub, y_test_sub, test_label)\n",
    "        X_flip_per_class_train = create_adv_wrt_class(X_train_sub, y_train_sub, train_label)\n",
    "#         X_flip_per_class_random = create_adv_wrt_class(X_random, y_random, random_label)\n",
    "#         X_flip_per_class_random_normal = create_adv_wrt_class(X_random_normal, y_random_normal, random_normal_label)\n",
    "        \n",
    "    if(from_cls != -1):\n",
    "            print('From Class ' + str(from_cls) + '\\n')\n",
    "            X_test_sub, y_test_sub, X_flip_per_class_test = get_class(X_test_sub, y_test_sub,\n",
    "                                                                      from_cls,X_flip_per_class_test)\n",
    "            X_train_sub, y_train_sub, X_flip_per_class_train= get_class(X_train_sub, y_train_sub,\n",
    "                                                                       from_cls,X_flip_per_class_train)\n",
    "#             X_random, y_random, X_flip_per_class_random = get_class(X_random, y_random, \n",
    "#                                                                      from_cls, X_flip_per_class_random)\n",
    "#             X_random_normal, y_random_normal, X_flip_per_class_random_normal = get_class(\n",
    "#                 X_random_normal, y_random_normal,  from_cls, X_flip_per_class_random_normal)\n",
    "            print('Test Data:' + str(y_test_sub.shape[0]))\n",
    "            print('Train Data: ' + str(y_train_sub.shape[0]))\n",
    "#             print('Random Data: ' + str(y_random.shape[0]))\n",
    "#             print('Random Normal Data: ' + str(y_random_normal.shape[0]))\n",
    "        \n",
    "    _, X_flip_test = give_m2_ans(X_test_sub, X_flip_per_class_test, to_cls)\n",
    "    _, X_flip_train = give_m2_ans(X_train_sub, X_flip_per_class_train, to_cls)\n",
    "#     _, X_flip_random = give_m2_ans(X_random,X_flip_per_class_random, to_cls)\n",
    "#     _, X_flip_random_normal = give_m2_ans(X_random_normal, X_flip_per_class_random_normal,to_cls)\n",
    "\n",
    "    l2_test = get_l2_at_layer(X_flip_test,X_test_sub, layer)\n",
    "    l2_train = get_l2_at_layer(X_flip_train, X_train_sub, layer)\n",
    "#     l2_random = get_l2_at_layer(X_flip_random,X_random, layer)\n",
    "#     l2_random_normal = get_l2_at_layer(X_flip_random_normal,X_random_normal, layer)\n",
    "\n",
    "    return l2_test, l2_train\n",
    "\n",
    "def restore_flip(method, epochs, n,from_cls=-1, to_cls = -1, layer= -1):\n",
    "    test_label = make_label(\"test\", method, epochs,n, False)\n",
    "    train_label = make_label(\"train\", method, epochs,n, False)\n",
    "    random_label = make_label(\"random\", method, epochs,n, False)\n",
    "    random_normal_label = make_label(\"random_normal\", method, epochs,n, False)\n",
    "#     data_label_random, data_label_random_normal = make_label(\"_\", method, epochs,n, True)\n",
    "    \n",
    "    X_test_sub, y_test_sub, X_train_sub, y_train_sub = make_data(n)\n",
    "#     X_random, y_random, X_random_normal, y_random_normal = restore_random_data(data_label_random, data_label_random_normal)\n",
    "    \n",
    "    \n",
    "    if(method==2):\n",
    "        X_flip_per_class_test = load_from_txt(get_flip_path(test_label))\n",
    "        X_flip_per_class_train = load_from_txt(get_flip_path(train_label))\n",
    "#         X_flip_per_class_random = load_from_txt(get_flip_path(random_label))\n",
    "#         X_flip_per_class_random_normal = load_from_txt(get_flip_path(random_normal_label))\n",
    "            \n",
    "        if(from_cls != -1):\n",
    "            print('From Class ' + str(from_cls) + '\\n')\n",
    "            X_test_sub, y_test_sub, X_flip_per_class_test = get_class(X_test_sub, y_test_sub,\n",
    "                                                                      from_cls,X_flip_per_class_test)\n",
    "            X_train_sub, y_train_sub, X_flip_per_class_train= get_class(X_train_sub, y_train_sub,\n",
    "                                                                        from_cls,X_flip_per_class_train)\n",
    "#             X_random, y_random, X_flip_per_class_random = get_class(X_random, y_random, \n",
    "#                                                                      from_cls, X_flip_per_class_random)\n",
    "#             X_random_normal, y_random_normal, X_flip_per_class_random_normal = get_class(\n",
    "#                 X_random_normal, y_random_normal,  from_cls, X_flip_per_class_random_normal)\n",
    "            print('Test Data:' + str(y_test_sub.shape[0]))\n",
    "            print('Train Data: ' + str(y_train_sub.shape[0]))\n",
    "#             print('Random Data: ' + str(y_random.shape[0]))\n",
    "#             print('Random Normal Data: ' + str(y_random_normal.shape[0]))\n",
    "            \n",
    "    _, X_flip_test = give_m2_ans(X_test_sub, X_flip_per_class_test, to_cls)\n",
    "    _, X_flip_train = give_m2_ans(X_train_sub, X_flip_per_class_train, to_cls)\n",
    "#     _, X_flip_random = give_m2_ans(X_random,X_flip_per_class_random, to_cls)\n",
    "#     _, X_flip_random_normal = give_m2_ans(X_random_normal, X_flip_per_class_random_normal,to_cls)\n",
    "\n",
    "    l2_test = get_l2_at_layer(X_flip_test,X_test_sub, layer)\n",
    "    l2_train = get_l2_at_layer(X_flip_train, X_train_sub, layer)\n",
    "#     l2_random = get_l2_at_layer(X_flip_random,X_random, layer)\n",
    "#     l2_random_normal = get_l2_at_layer(X_flip_random_normal,X_random_normal, layer)\n",
    "\n",
    "    return l2_test, l2_train\n",
    "\n",
    "def plot_data_graph(l2_test, l2_train, l2_random, l2_random_normal, n, from_cls, to_cls):\n",
    "    %matplotlib inline\n",
    "    t = np.arange(1,n+1, 1)\n",
    "    plt.plot(t, l2_test[:n], 'r--', t, l2_train[:n],'b--', t, l2_random[:n], 'y--', l2_random_normal[:n], 'k--')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='Train Data')\n",
    "    red_patch = mpatches.Patch(color='red', label='Test Data')\n",
    "    yellow_patch = mpatches.Patch(color='yellow', label='Random Data')\n",
    "    black_patch = mpatches.Patch(color='black', label='Random Normal Data')\n",
    "    plt.legend(handles=[blue_patch, red_patch, yellow_patch, black_patch])\n",
    "    plt.title(\"From \" + str(from_cls) + \" to \" + str(to_cls))\n",
    "    plt.xlabel(\"Examples\")\n",
    "    plt.ylabel(\"L2 Norm\")\n",
    "    \n",
    "    plt.show()    \n",
    "\n",
    "def plot_data_hist(l2,n,title):\n",
    "    %matplotlib inline\n",
    "    plt.hist(l2,n)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Distance\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_hists_without_random(l2_test, l2_train, n,from_cls,to_cls,lyr):\n",
    "    plot_data_hist(l2_test, l2_test.shape[0], \"Train Data\\n From \" + str(from_cls) + \" to \" + str(to_cls) + \" layer \" + str(lyr))\n",
    "    plot_data_hist(l2_train, l2_train.shape[0], \"Test Data\\n From \" + str(from_cls) + \" to \" + str(to_cls)+ \" layer \" + str(lyr))\n",
    "    \n",
    "    \n",
    "# one hot encoding, basically creates hte si\n",
    "def _to_categorical(x, n_classes):\n",
    "    x = np.array(x, dtype=int).ravel()\n",
    "    n = x.shape[0]\n",
    "    ret = np.zeros((n, n_classes))\n",
    "    ret[np.arange(n), x] = 1\n",
    "    return ret\n",
    "\n",
    "def plot_data_graph_without_random(l2_test, l2_train, n, from_cls, to_cls,lyr):\n",
    "    %matplotlib inline\n",
    "    n = min(l2_test.shape[0], l2_train.shape[0])\n",
    "    t = np.arange(1,n+1, 1)\n",
    "    plt.plot(t, l2_test[:n], 'r--', t, l2_train[:n],'b--')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='Train Data')\n",
    "    red_patch = mpatches.Patch(color='red', label='Test Data')\n",
    "    yellow_patch = mpatches.Patch(color='yellow', label='Random Data')\n",
    "    black_patch = mpatches.Patch(color='black', label='Random Normal Data')\n",
    "    plt.legend(handles=[blue_patch, red_patch, yellow_patch, black_patch])\n",
    "    plt.title(\"From \" + str(from_cls) + \" to \" + str(to_cls)+ \" layer \" + str(lyr))\n",
    "    plt.xlabel(\"Examples\")\n",
    "    plt.ylabel(\"L2 Norm\")\n",
    "    \n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "    \n",
    "def restore_random_data(lr, lrn):\n",
    "    Xr = load_from_txt(get_flip_path(lr))\n",
    "    Xrn = load_from_txt(get_flip_path(lrn))\n",
    "    y_random_normal = sess.run(env.ybar, feed_dict={env.x: Xrn,env.training: False})\n",
    "    y_random_normal = _to_categorical(np.argmax(y_random_normal,axis=1), n_classes)\n",
    "    y_random = sess.run(env.ybar, feed_dict={env.x: Xr,env.training: False})\n",
    "    y_random = _to_categorical(np.argmax(y_random, axis=1), n_classes)\n",
    "    \n",
    "    return Xr, y_random, Xrn, y_random_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading CIFAR10\n",
      "\n",
      "Loading pre-Shuffled training data\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, X_valid, y_valid = load_data(os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Dummy:\n",
    "    pass\n",
    "env = Dummy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     1
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model(x, logits=False, training=False, layer = -1):\n",
    "    conv0 = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3],\n",
    "                             padding='same', name='conv0',\n",
    "                             activation=tf.nn.relu)\n",
    "    \n",
    "    pool0 = tf.layers.max_pooling2d(conv0, pool_size=[2, 2],\n",
    "                                    strides=2, name='pool0')\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(pool0, filters=64,\n",
    "                             kernel_size=[3, 3], padding='same',\n",
    "                             name='conv1', activation=tf.nn.relu)\n",
    "   \n",
    " \n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(conv1, pool_size=[2, 2],\n",
    "                                    strides=2, name='pool1')\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(pool1, filters=128,\n",
    "                             kernel_size=[1,1], padding='same',\n",
    "                             name='conv2', activation=tf.nn.relu)\n",
    "    \n",
    "\n",
    "    \n",
    "    flat = tf.reshape(conv2, [-1, 8*8*128], name='flatten')\n",
    "    \n",
    "    dense1 = tf.layers.dense(flat, units= 1024, activation=tf.nn.relu,\n",
    "                            name='dense1')\n",
    "    \n",
    "    dense2 = tf.layers.dense(dense1, units=128, activation=tf.nn.relu,\n",
    "                            name='dense2')\n",
    "    logits_ = tf.layers.dense(dense2, units=10, name='logits') #removed dropout\n",
    "    \n",
    "    y = tf.nn.softmax(logits_, name='ybar')\n",
    "    \n",
    "    \n",
    "    if logits:\n",
    "        return y, logits_\n",
    "    \n",
    "    y = tf.cond(tf.equal(layer, tf.constant(-1)), lambda: y, lambda: y)\n",
    "    y = tf.cond(tf.equal(layer, tf.constant(0)), lambda: x, lambda: y)\n",
    "    y = tf.cond(tf.equal(layer, tf.constant(1)), lambda: pool0, lambda: y)\n",
    "    y = tf.cond(tf.equal(layer, tf.constant(2)), lambda: pool1, lambda: y)\n",
    "    y = tf.cond(tf.equal(layer, tf.constant(3)), lambda: dense1, lambda: y)\n",
    "    y = tf.cond(tf.equal(layer, tf.constant(4)), lambda: dense2, lambda: y)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We need a scope since the inference graph will be reused later\n",
    "with tf.variable_scope('model'):\n",
    "    env.x = tf.placeholder(tf.float32, (None, img_rows, img_cols,\n",
    "                                        img_chas), name='x')\n",
    "    env.y = tf.placeholder(tf.float32, (None, n_classes), name='y')\n",
    "    env.training = tf.placeholder(bool, (), name='mode')\n",
    "\n",
    "    env.ybar, logits = model(env.x, logits=True,\n",
    "                             training=env.training)\n",
    "    \n",
    "    z = tf.argmax(env.y, axis=1)\n",
    "    zbar = tf.argmax(env.ybar, axis=1)\n",
    "    env.count = tf.cast(tf.equal(z, zbar), tf.float32)\n",
    "    env.acc = tf.reduce_mean(env.count, name='acc')\n",
    "\n",
    "    xent = tf.nn.softmax_cross_entropy_with_logits(labels=env.y,\n",
    "                                                   logits=logits)\n",
    "    env.loss = tf.reduce_mean(xent, name='loss')\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    env.optim = tf.train.AdamOptimizer(beta1=0.9, beta2=0.999, epsilon=1e-08,).minimize(env.loss) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('model', reuse=True):\n",
    "    env.lyr= tf.placeholder(tf.int32)\n",
    "    env.layer_out = model(env.x, layer=env.lyr, logits=False ,training = env.training )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0,
     4
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_model(label):\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess,  './models/cifar/' + label)\n",
    "    \n",
    "def restore_model(label):\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './models/cifar/' + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     23
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _evaluate(X_data, y_data, env):\n",
    "    print('\\nEvaluating')\n",
    "    n_sample = X_data.shape[0]\n",
    "    batch_size = 128\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    loss, acc = 0, 0\n",
    "    ns = 0\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        batch_loss, batch_count, batch_acc = sess.run(\n",
    "            [env.loss, env.count, env.acc],\n",
    "            feed_dict={env.x: X_data[start:end],\n",
    "                       env.y: y_data[start:end],\n",
    "                       env.training: False})\n",
    "        loss += batch_loss*batch_size\n",
    "        print('batch count: {0}'.format(np.sum(batch_count)))\n",
    "        ns+=batch_size\n",
    "        acc += batch_acc*batch_size\n",
    "    loss /= ns\n",
    "    acc /= ns\n",
    "#     print (ns)\n",
    "#     print (n_sample)\n",
    "    print(' loss: {0:.4f} acc: {1:.4f}'.format(loss, acc))\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     15,
     37
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _predict(X_data, env):\n",
    "    print('\\nPredicting')\n",
    "    n_sample = X_data.shape[0]\n",
    "    batch_size = 128\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    yval = np.empty((X_data.shape[0], n_classes))\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        batch_y = sess.run(env.ybar, feed_dict={\n",
    "            env.x: X_data[start:end], env.training: False})\n",
    "        yval[start:end] = batch_y\n",
    "    return yval\n",
    "\n",
    "def train(label):\n",
    "    print('\\nTraining')\n",
    "    n_sample = X_train.shape[0]\n",
    "    batch_size = 128\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    n_epoch = 50\n",
    "    for epoch in range(n_epoch):\n",
    "        print('Epoch {0}/{1}'.format(epoch+1, n_epoch))\n",
    "        for ind in range(n_batch):\n",
    "            print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "            start = ind*batch_size\n",
    "            end = min(n_sample, start+batch_size)\n",
    "            sess.run(env.optim, feed_dict={env.x: X_train[start:end],\n",
    "                                           env.y: y_train[start:end],\n",
    "                                           env.training: True})\n",
    "        if(epoch%5 == 0):\n",
    "            model_label = label+ '{0}'.format(epoch)\n",
    "            print(\"saving model \" + model_label)\n",
    "            save_model(model_label)\n",
    "            \n",
    "    save_model(label)\n",
    "\n",
    "def train_again(X, y, epochs):\n",
    "    #Not making batches, do that if size > 128\n",
    "    for i in range(X.shape[0]):\n",
    "        for e in range(epochs):\n",
    "            sess.run(env.optim, feed_dict={env.x: [X[i]],\n",
    "                                           env.y: [y[i]],\n",
    "                                           env.training: True})\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_adv_wrt_class(X, Y, label = None):\n",
    "    print('\\nCrafting adversarial')\n",
    "    n_sample = X.shape[0]\n",
    "    pred = np.argmax(Y,axis=1)\n",
    "    batch_size = 1\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    n_epoch = 20\n",
    "    x_adv_shape = list(X.shape)[1:]\n",
    "    x_adv_shape = np.append(np.append(n_sample,n_classes),x_adv_shape)\n",
    "    X_adv = np.empty(x_adv_shape)\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        tmp = sess.run(env.x_adv_wrt_class, feed_dict={env.x: X[start:end],\n",
    "                                             env.y: Y[start:end],\n",
    "                                             env.training: False})\n",
    "        tmp[pred[start]] = X[start]\n",
    "        X_adv[start:end] = tmp\n",
    "    if(label != None):\n",
    "        print('\\nSaving adversarial')\n",
    "        os.makedirs('data', exist_ok=True)\n",
    "        save_as_txt(get_flip_path(label), X_adv)\n",
    "    return X_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_adv(X, Y, label):\n",
    "    print('\\nCrafting adversarial')\n",
    "    n_sample = X.shape[0]\n",
    "    batch_size = 1\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    n_epoch = 20\n",
    "    X_adv = np.empty_like(X)\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        tmp, all_flipped = sess.run([env.x_adv, env.all_flipped], feed_dict={env.x: X[start:end],\n",
    "                                             env.y: Y[start:end],\n",
    "                                             env.training: False})\n",
    "        X_adv[start:end] = tmp\n",
    "    print('\\nSaving adversarial')\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    save_as_txt(get_flip_path(label), X_adv)\n",
    "    return X_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/cifar/cifar_with_cnn200\n"
     ]
    }
   ],
   "source": [
    "method = 2\n",
    "n = 1000\n",
    "epochs = 200\n",
    "label=\"cifar_with_cnn\"\n",
    "lyrs= 4\n",
    "\n",
    "# train(label)\n",
    "restore_model(label + str(epochs))\n",
    "# _evaluate(X_train, y_train, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b49ea4c88337>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlyrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mplot_all_data_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-5e2b9b1f8904>\u001b[0m in \u001b[0;36mplot_all_data_graph\u001b[0;34m(method, epochs, n, lyr)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mto_cls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_cls\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mto_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0ml2_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_flip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfrom_cls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_cls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlyr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0;31m#There might be a prob. here! since lens are diff, solved it inside the func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mplot_data_graph_without_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfrom_cls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_cls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlyr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-5e2b9b1f8904>\u001b[0m in \u001b[0;36mrestore_flip\u001b[0;34m(method, epochs, n, from_cls, to_cls, layer)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mX_flip_per_class_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_from_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_flip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mX_flip_per_class_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_from_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_flip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;31m#         X_flip_per_class_random = load_from_txt(get_flip_path(random_label))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Decision-Flip-Experiments/saveloader.py\u001b[0m in \u001b[0;36mload_from_txt\u001b[0;34m(label)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_from_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34mb'0x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_label = make_label(\"train\", method, epochs,n, False)\n",
    "n_exs = 15 \n",
    "X = X_test[:n_exs]\n",
    "X_flip =  load_from_txt(get_flip_path(train_label))\n",
    "X_flip = X_flip[:n_exs]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(lyrs):\n",
    "    plot_all_data_graph(method,epochs,n,i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(gs[0,0])\n",
    "ax1.plot([1,2,3],[1,2,3])\n",
    "ax2 = plt.subplot(gs[0,1])\n",
    "ax3 = plt.subplot(gs[1, 0])\n",
    "ax4 = plt.subplot(gs[1,1])\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(20, 10.5)\n",
    "plt.savefig('test.png', dpi=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([[3,4],[5,6]])\n",
    "b = np.array([1,2])\n",
    "d = np.array([5,6])\n",
    "c = [a,b]\n",
    "np.sum(a,axis=0)/len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_centroids(X,Xs,n=None):\n",
    "    if n is not None:\n",
    "        X = X[:n]\n",
    "    ys = _predict(Xs,env)\n",
    "    y = _predict(X,env)\n",
    "    y_ = np.argmax(y, axis=1)\n",
    "    X_centroids = np.empty([n_classes, img_rows, img_cols, img_chas])\n",
    "    for c in range(n_classes):\n",
    "        Xt,yt = get_class(Xs,ys,c)\n",
    "        print(len(Xt))\n",
    "        X_centroids[c] = np.sum(Xt, axis =0 )/len(Xt)\n",
    "    ans = np.empty_like(X)\n",
    "    for i in range(len(X)):\n",
    "        ans[i] = X_centroids[y_[i]]\n",
    "    return ans    \n",
    "    \n",
    "def get_class(X, Y, cls, Z=None):\n",
    "    p = np.argmax(Y, axis=1)\n",
    "    indices = np.where(p == cls)\n",
    "    if Z is not None:\n",
    "        return X[indices], Y[indices], Z[indices]\n",
    "    else:\n",
    "        return X[indices], Y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Using X_own as the centroid of the class\n",
    "def func(X,X_flip):\n",
    "    l2_flip = np.empty([n_exs,lyrs], dtype = np.float32)\n",
    "    l2_own_cls = np.empty([n_exs,lyrs], dtype = np.float32)\n",
    "    X_own = get_centroids(X,X_test[3000:4000])\n",
    "    \n",
    "    _, X_flip_min = give_m2_ans(X,X_flip)\n",
    "#     print(X_flip_min.shape)\n",
    "#     print(X_own.shape)\n",
    "    for lyr in range(lyrs):\n",
    "        l2_flip[:,lyr] = get_l2_at_layer(X,X_flip_min,sess, env,lyr)\n",
    "        l2_own_cls[:,lyr] = get_l2_at_layer(X,X_own,sess, env,lyr)\n",
    "    \n",
    "    return l2_flip, l2_own_cls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "method = 2\n",
    "n = 1000\n",
    "epochs = 200\n",
    "label=\"cifar_with_cnn\"\n",
    "lyrs= 4\n",
    "train_label = make_label(\"train\", method, epochs,n, False)\n",
    "n_exs = 15 \n",
    "X = X_test[:n_exs]\n",
    "X_flip =  load_from_txt(get_flip_path(train_label))\n",
    "X_flip = X_flip[:n_exs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      " batch 8/8\n",
      "Predicting\n",
      "97atch 1/1\n",
      "95\n",
      "99\n",
      "83\n",
      "115\n",
      "101\n",
      "100\n",
      "99\n",
      "96\n",
      "115\n",
      "(15, 32, 32, 3)\n",
      "3072\n",
      "(15, 32, 32, 3)\n",
      "3072\n",
      "(15, 16, 16, 32)\n",
      "8192\n",
      "(15, 16, 16, 32)\n",
      "8192\n",
      "(15, 8, 8, 64)\n",
      "4096\n",
      "(15, 8, 8, 64)\n",
      "4096\n",
      "(15, 1024)\n",
      "1024\n",
      "(15, 1024)\n",
      "1024\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-587425e98407>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_flip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "ans = func(X,X_flip)\n",
    "print(ans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

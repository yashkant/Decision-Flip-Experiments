{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     23,
     27,
     44,
     51,
     56,
     71,
     81,
     87,
     97,
     105,
     118,
     142,
     147,
     157,
     160,
     163,
     183,
     224,
     234,
     284,
     308,
     323,
     332,
     338,
     345
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/yash/Desktop/Decision-Flip-Experiments')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn import ModeKeys, Estimator\n",
    "import _pickle as pickle\n",
    "from scipy.misc import imread\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from fgsm_cifar import fgsm\n",
    "from fgsm_cifar_wrt_class import fgsm_wrt_class\n",
    "import sys  \n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "img_rows = 32\n",
    "img_cols = 32\n",
    "img_chas = 3\n",
    "input_shape = (img_rows, img_cols, img_chas)\n",
    "n_classes = 10\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open('data/misc/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('data/misc/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "sd = 'shape_dict'\n",
    "# save_obj({},sd)\n",
    "\n",
    "def plot_all_data_graph(method,epochs,n):\n",
    "    for from_cls in range(2):\n",
    "        for to_cls in range(n_classes):\n",
    "            if(from_cls != to_cls):\n",
    "                l2_test, l2_train, l2_random, l2_random_normal = restore_flip(method,epochs,n,from_cls,to_cls)\n",
    "                #There might be a prob. here! since lens are diff, solved it inside the func\n",
    "                plot_data_graph_without_random(l2_test, l2_train, l2_random, l2_random_normal, n,from_cls,to_cls)\n",
    "                plot_hists_without_random(l2_test, l2_train, n,from_cls,to_cls)\n",
    "                \n",
    "\n",
    "def save_as_txt(label,ar):\n",
    "    d=load_obj(sd)\n",
    "    d[label] = ar.shape\n",
    "    save_obj(d,sd)\n",
    "    X = ar.reshape((ar.shape[0],-1))\n",
    "    np.savetxt(label , X)\n",
    "\n",
    "def load_from_txt(label):\n",
    "    d=load_obj(sd)\n",
    "    X= np.loadtxt(label)\n",
    "    return X.reshape(d[label])\n",
    "\n",
    "def load_CIFAR10(ROOT):\n",
    "  \"\"\" load all of cifar \"\"\"\n",
    "  xs = []\n",
    "  ys = []\n",
    "  for b in range(1,6):\n",
    "    f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "    X, Y = load_CIFAR_batch(f)\n",
    "    xs.append(X)\n",
    "    ys.append(Y)    \n",
    "  Xtr = np.concatenate(xs)\n",
    "  Ytr = np.concatenate(ys)\n",
    "  del X, Y\n",
    "  Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "  return Xtr, Ytr, Xte, Yte\n",
    "\n",
    "def load_CIFAR_batch(filename):\n",
    "  \"\"\" load single batch of cifar \"\"\"\n",
    "  with open(filename, 'rb') as f:\n",
    "    datadict = pickle.load(f,encoding='latin1')\n",
    "    X = datadict['data']\n",
    "    Y = datadict['labels']\n",
    "    X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "    Y = np.array(Y)\n",
    "    return X, Y\n",
    "\n",
    "def find_l2(X_test, X_adv):\n",
    "    a=X_test.reshape(-1,32*32*3)\n",
    "    b=X_adv.reshape(-1,32*32*3)\n",
    "    l2_unsquared = np.sum(np.square(a-b),axis=1)\n",
    "    return l2_unsquared\n",
    "\n",
    "def find_l2_batch(X_test, X_adv):\n",
    "    ans = np.zeros([X_test.shape[0],n_classes], dtype = np.float32)\n",
    "    for i in range(X_test.shape[0]):\n",
    "        for j in range(n_classes):\n",
    "            ans[i][j] = find_l2(X_test[i], X_adv[i][j])\n",
    "    return ans\n",
    "\n",
    "# m2 is the grouped flipping\n",
    "# m1 is the single flipping\n",
    "#This method returns the distance of each predictions from repective test points calculated by m1 and m2 resp. \n",
    "def find_m1_m2(X_test,X_adv_one,X_adv_test):\n",
    "    dist_adv_m1 = find_l2(X_test, X_adv_one)\n",
    "    b = find_l2_batch(X_test, X_adv_test)\n",
    "    dist_adv_m2 = np.partition(b,axis=1,kth=1)[:,1]\n",
    "    return np.sqrt(dist_adv_m1), np.sqrt(dist_adv_m2)\n",
    "\n",
    "# Give this function X_adv_test it gives you the points corresponding to\n",
    "# each example having min dists and their indices \n",
    "def give_m2_ans(X_test, X_adv_test,cls= -1):\n",
    "    if(cls == -1):\n",
    "        dists = find_l2_batch(X_test, X_adv_test)\n",
    "        second_min_indices = np.partition(dists, axis=1, kth=1)[:,1]\n",
    "        for i in range(X_test.shape[0]):\n",
    "            second_min_indices[i] = (np.where(second_min_indices[i] == dists[i])[0][0])\n",
    "        ans = np.empty([X_adv_test.shape[0], img_rows, img_cols, img_chas])\n",
    "        for i in range(ans.shape[0]):\n",
    "            ans[i] = X_adv_test[i][second_min_indices[i].astype(int)]\n",
    "        return second_min_indices, ans\n",
    "    else:\n",
    "        return 0, get_flipped_class(X_adv_test,cls)\n",
    "\n",
    "def remove_zeroes(X):\n",
    "    indices = np.where(X == 0)[0]\n",
    "    return np.delete(X,indices)\n",
    "\n",
    "def get_class(X,Y,Z, cls):\n",
    "    p=np.argmax(Y, axis=1)\n",
    "    indices = np.where(p==cls)\n",
    "    return X[indices], Y[indices], Z[indices]\n",
    "\n",
    "def get_class_indices(X,cls):\n",
    "    p = _predict(X,env)\n",
    "    p = np.argmax(p, axis =1)\n",
    "    return np.where(p==cls)\n",
    "\n",
    "def make_label(i,m,e,n,r):\n",
    "    if(r == False):\n",
    "        return i + \"_m\" + str(m) + \"_e\" + str(e) + \"_n\" + str(n)\n",
    "    else:\n",
    "        base = i + \"_m\" + str(m) + \"_e\" + str(e) + \"_n\" + str(n) + \"_r\"\n",
    "        lrn = base + \"normal\"\n",
    "        return base, lrn\n",
    "\n",
    "def get_flipped_class(X_adv,cls):\n",
    "    return X_adv[:,cls]\n",
    "    \n",
    "    \n",
    "\n",
    "def make_data(n):\n",
    "    X_test_sub = X_test[:n]\n",
    "    X_train_sub = X_train[:n]\n",
    "    y_train_sub = sess.run(env.ybar, feed_dict={env.x: X_train_sub,env.training: False})\n",
    "    y_train_sub = _to_categorical(np.argmax(y_train_sub, axis=1), n_classes)\n",
    "    y_test_sub = sess.run(env.ybar, feed_dict={env.x:X_test_sub ,env.training: False})\n",
    "    y_test_sub = _to_categorical(np.argmax(y_test_sub, axis=1), n_classes)\n",
    "    \n",
    "    return X_test_sub, y_test_sub, X_train_sub, y_train_sub\n",
    "\n",
    "def get_flip_path(l):\n",
    "    return 'data/cifar/' + l+ '.txt'\n",
    "\n",
    "def get_misc_path(l):\n",
    "    return 'data/misc/' + l+ '.txt'\n",
    "\n",
    "def random_normal_func(X, n, save, lr, lrn):\n",
    "    X=X.reshape(-1,img_rows*img_cols*img_chas)\n",
    "    mean, std = np.mean(X, axis=0), np.std(X,axis=0)\n",
    "    randomX = np.zeros([n,X[0].size])\n",
    "    for i in range(X[0].size):\n",
    "        randomX[:,i] = np.random.normal(mean[i],std[i],n)\n",
    "    randomX = randomX.reshape(-1,img_rows,img_cols,img_chas)\n",
    "    X_random_normal = randomX\n",
    "    ans = sess.run(env.ybar, feed_dict={env.x: randomX,env.training: False})\n",
    "    y_random_normal = _to_categorical(np.argmax(ans,axis=1), n_classes)\n",
    "    X_random = np.random.rand(n,img_rows,img_cols,img_chas)\n",
    "    y_random = sess.run(env.ybar, feed_dict={env.x: X_random,env.training: False})\n",
    "    y_random = _to_categorical(np.argmax(y_random, axis=1), n_classes)\n",
    "    \n",
    "    if(save):\n",
    "        save_as_txt(get_flip_path(lr),X_random)\n",
    "        save_as_txt(get_flip_path(lrn),X_random_normal)\n",
    "    \n",
    "    return X_random, y_random, X_random_normal, y_random_normal  \n",
    "\n",
    "def run_flip(method, epochs, n, cls=-1):\n",
    "    save_obj({},sd)\n",
    "    test_label = make_label(\"test\", method, epochs,n, False)\n",
    "    train_label = make_label(\"train\", method, epochs,n, False)\n",
    "    random_label = make_label(\"random\", method, epochs,n, False)\n",
    "    random_normal_label = make_label(\"random_normal\", method, epochs,n, False)\n",
    "    data_label_random, data_label_random_normal = make_label(\"_\", method, epochs,n, True)\n",
    "    \n",
    "    X_test_sub, y_test_sub, X_train_sub, y_train_sub = make_data(n)\n",
    "    X_random, y_random, X_random_normal, y_random_normal = random_normal_func(X_train,n, True, \n",
    "                                                                              data_label_random, data_label_random_normal)\n",
    "    if(cls < -2 or cls > 9):\n",
    "        print(\"Invalid Params\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    if(method==1):\n",
    "        X_flip_test = create_adv(X_test_sub, y_test_sub, test_label)\n",
    "        X_flip_train = create_adv(X_train_sub, y_train_sub, train_label)\n",
    "        X_flip_random = create_adv(X_random, y_random, random_label)\n",
    "        X_flip_random_normal = create_adv(X_random_normal, y_random_normal, random_normal_label)\n",
    "    \n",
    "    if(method==2):\n",
    "        X_flip_per_class_test = create_adv_wrt_class(X_test_sub, y_test_sub, test_label)\n",
    "        X_flip_per_class_train = create_adv_wrt_class(X_train_sub, y_train_sub, train_label)\n",
    "        X_flip_per_class_random = create_adv_wrt_class(X_random, y_random, random_label)\n",
    "        X_flip_per_class_random_normal = create_adv_wrt_class(X_random_normal, y_random_normal, random_normal_label)\n",
    "        \n",
    "        _, X_flip_test = give_m2_ans(X_test_sub, X_flip_per_class_test, cls)\n",
    "        _, X_flip_train = give_m2_ans(X_train_sub, X_flip_per_class_train, cls)\n",
    "        _, X_flip_random = give_m2_ans(X_random,X_flip_per_class_random, cls)\n",
    "        _, X_flip_random_normal = give_m2_ans(X_random_normal, X_flip_per_class_random_normal,cls)\n",
    "\n",
    "    \n",
    "    l2_test = find_l2(X_flip_test,X_test_sub)\n",
    "    l2_train = find_l2(X_flip_train, X_train_sub)\n",
    "    l2_random = find_l2(X_flip_random,X_random)\n",
    "    l2_random_normal = find_l2(X_flip_random_normal,X_random_normal)\n",
    "\n",
    "    return l2_test, l2_train, l2_random, l2_random_normal\n",
    "\n",
    "def restore_random_data(lr, lrn):\n",
    "    Xr = load_from_txt(get_flip_path(lr))\n",
    "    Xrn = load_from_txt(get_flip_path(lrn))\n",
    "    y_random_normal = sess.run(env.ybar, feed_dict={env.x: Xrn,env.training: False})\n",
    "    y_random_normal = _to_categorical(np.argmax(y_random_normal,axis=1), n_classes)\n",
    "    y_random = sess.run(env.ybar, feed_dict={env.x: Xr,env.training: False})\n",
    "    y_random = _to_categorical(np.argmax(y_random, axis=1), n_classes)\n",
    "    \n",
    "    return Xr, y_random, Xrn, y_random_normal\n",
    "\n",
    "def restore_flip(method, epochs, n,from_cls=-1, to_cls = -1):\n",
    "    test_label = make_label(\"test\", method, epochs,n, False)\n",
    "    train_label = make_label(\"train\", method, epochs,n, False)\n",
    "    random_label = make_label(\"random\", method, epochs,n, False)\n",
    "    random_normal_label = make_label(\"random_normal\", method, epochs,n, False)\n",
    "    data_label_random, data_label_random_normal = make_label(\"_\", method, epochs,n, True)\n",
    "    \n",
    "    X_test_sub, y_test_sub, X_train_sub, y_train_sub = make_data(n)\n",
    "    X_random, y_random, X_random_normal, y_random_normal = restore_random_data(data_label_random, data_label_random_normal)\n",
    "    \n",
    "    \n",
    "    if(method==1):\n",
    "        X_flip_test =  load_from_txt(get_flip_path(test_label))\n",
    "        X_flip_train = load_from_txt(get_flip_path(train_label))\n",
    "        X_flip_random = load_from_txt(get_flip_path(random_label))\n",
    "        X_flip_random_normal = load_from_txt(get_flip_path(random_normal_label))\n",
    "    \n",
    "    if(method==2):\n",
    "        X_flip_per_class_test = load_from_txt(get_flip_path(test_label))\n",
    "        X_flip_per_class_train = load_from_txt(get_flip_path(train_label))\n",
    "        X_flip_per_class_random = load_from_txt(get_flip_path(random_label))\n",
    "        X_flip_per_class_random_normal = load_from_txt(get_flip_path(random_normal_label))\n",
    "            \n",
    "        if(from_cls != -1):\n",
    "            print('From Class ' + str(from_cls) + '\\n')\n",
    "            X_test_sub, y_test_sub, X_flip_per_class_test = get_class(X_test_sub, y_test_sub,\n",
    "                                                                     X_flip_per_class_test, from_cls)\n",
    "            X_train_sub, y_train_sub, X_flip_per_class_train= get_class(X_train_sub, y_train_sub,\n",
    "                                                                       X_flip_per_class_train, from_cls)\n",
    "            X_random, y_random, X_flip_per_class_random = get_class(X_random, y_random, \n",
    "                                                                    X_flip_per_class_random, from_cls)\n",
    "            X_random_normal, y_random_normal, X_flip_per_class_random_normal = get_class(\n",
    "                X_random_normal, y_random_normal, X_flip_per_class_random_normal, from_cls)\n",
    "            print('Test Data:' + str(y_test_sub.shape[0]))\n",
    "            print('Train Data: ' + str(y_train_sub.shape[0]))\n",
    "            print('Random Data: ' + str(y_random.shape[0]))\n",
    "            print('Random Normal Data: ' + str(y_random_normal.shape[0]))\n",
    "        \n",
    "        _, X_flip_test = give_m2_ans(X_test_sub, X_flip_per_class_test, to_cls)\n",
    "        _, X_flip_train = give_m2_ans(X_train_sub, X_flip_per_class_train, to_cls)\n",
    "        _, X_flip_random = give_m2_ans(X_random,X_flip_per_class_random, to_cls)\n",
    "        _, X_flip_random_normal = give_m2_ans(X_random_normal, X_flip_per_class_random_normal,to_cls)\n",
    "        \n",
    "    l2_test = find_l2(X_flip_test,X_test_sub)\n",
    "    l2_train = find_l2(X_flip_train, X_train_sub)\n",
    "    l2_random = find_l2(X_flip_random,X_random)\n",
    "    l2_random_normal = find_l2(X_flip_random_normal,X_random_normal)\n",
    "\n",
    "    return l2_test, l2_train, l2_random, l2_random_normal\n",
    "\n",
    "def count_clear(l2_test, l2_train, l2_random, l2_random_normal):\n",
    "    nz_test = np.count_nonzero(l2_test)\n",
    "    nz_train = np.count_nonzero(l2_train)\n",
    "    nz_random = np.count_nonzero(l2_random)\n",
    "    nz_random_normal = np.count_nonzero(l2_random_normal)\n",
    "\n",
    "    print ('\\n test: ' + str(nz_test))\n",
    "    print ('train: ' + str(nz_train))\n",
    "    print ('random: ' + str(nz_random))\n",
    "    print ('random normal: ' + str(nz_random_normal))\n",
    "\n",
    "    l2_test = remove_zeroes(l2_test)\n",
    "    l2_random = remove_zeroes(l2_random)\n",
    "    l2_random_normal = remove_zeroes(l2_random_normal)\n",
    "    l2_train = remove_zeroes(l2_train)\n",
    "\n",
    "    min_no = min(nz_test, nz_train)\n",
    "    l2_train = np.sqrt(l2_train[:min_no])\n",
    "    l2_test = np.sqrt(l2_test[:min_no])\n",
    "    l2_random = np.sqrt(l2_random[:min_no])\n",
    "    l2_random_normal = np.sqrt(l2_random_normal[:min_no])\n",
    "\n",
    "    return l2_test, l2_train, l2_random, l2_random_normal\n",
    "\n",
    "def plot_data_graph(l2_test, l2_train, l2_random, l2_random_normal, n, from_cls, to_cls):\n",
    "    %matplotlib inline\n",
    "    t = np.arange(1,n+1, 1)\n",
    "    plt.plot(t, l2_test[:n], 'r--', t, l2_train[:n],'b--', t, l2_random[:n], 'y--', l2_random_normal[:n], 'k--')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='Train Data')\n",
    "    red_patch = mpatches.Patch(color='red', label='Test Data')\n",
    "    yellow_patch = mpatches.Patch(color='yellow', label='Random Data')\n",
    "    black_patch = mpatches.Patch(color='black', label='Random Normal Data')\n",
    "    plt.legend(handles=[blue_patch, red_patch, yellow_patch, black_patch])\n",
    "    plt.title(\"From \" + str(from_cls) + \" to \" + str(to_cls))\n",
    "    plt.xlabel(\"Examples\")\n",
    "    plt.ylabel(\"L2 Norm\")\n",
    "    \n",
    "    plt.show()    \n",
    "\n",
    "def plot_data_hist(l2,n,title):\n",
    "    %matplotlib inline\n",
    "    plt.hist(l2,n)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Distance\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_hists_without_random(l2_test, l2_train, n,from_cls,to_cls):\n",
    "    plot_data_hist(l2_test, l2_test.shape[0], \"Train Data\\n From \" + str(from_cls) + \" to \" + str(to_cls))\n",
    "    plot_data_hist(l2_train, l2_train.shape[0], \"Test Data\\n From \" + str(from_cls) + \" to \" + str(to_cls))\n",
    "    \n",
    "    \n",
    "\n",
    "def _to_categorical(x, n_classes):\n",
    "    x = np.array(x, dtype=int).ravel()\n",
    "    n = x.shape[0]\n",
    "    ret = np.zeros((n, n_classes))\n",
    "    ret[np.arange(n), x] = 1\n",
    "    return ret\n",
    "\n",
    "def plot_data_graph_without_random(l2_test, l2_train, l2_random, l2_random_normal, n, from_cls, to_cls):\n",
    "    %matplotlib inline\n",
    "    n = min(l2_test.shape[0], l2_train.shape[0])\n",
    "    t = np.arange(1,n+1, 1)\n",
    "    plt.plot(t, l2_test[:n], 'r--', t, l2_train[:n],'b--')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='Train Data')\n",
    "    red_patch = mpatches.Patch(color='red', label='Test Data')\n",
    "    yellow_patch = mpatches.Patch(color='yellow', label='Random Data')\n",
    "    black_patch = mpatches.Patch(color='black', label='Random Normal Data')\n",
    "    plt.legend(handles=[blue_patch, red_patch, yellow_patch, black_patch])\n",
    "    plt.title(\"From \" + str(from_cls) + \" to \" + str(to_cls))\n",
    "    plt.xlabel(\"Examples\")\n",
    "    plt.ylabel(\"L2 Norm\")\n",
    "    \n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading CIFAR10\n",
      "utf-8\n"
     ]
    }
   ],
   "source": [
    "print('\\nLoading CIFAR10')\n",
    "ab=sys.getdefaultencoding()\n",
    "print(ab)\n",
    "cifar10_dir = 'cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "\n",
    "X_train = X_train.reshape(-1, img_rows, img_cols, img_chas)\n",
    "X_test = X_test.reshape(-1, img_rows, img_cols, img_chas)\n",
    "\n",
    "y_train = _to_categorical(y_train, n_classes)\n",
    "y_test = _to_categorical(y_test, n_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     12
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading pre-Shuffled training data\n"
     ]
    }
   ],
   "source": [
    "print('\\nLoading pre-Shuffled training data')\n",
    "ind = np.loadtxt(get_misc_path('ind'), dtype = int)\n",
    "X_train, y_train = X_train[ind], y_train[ind]\n",
    "\n",
    "# split training/validation dataset\n",
    "validation_split = 0.1\n",
    "n_train = int(X_train.shape[0]*(1-validation_split))\n",
    "X_valid = X_train[n_train:]\n",
    "X_train = X_train[:n_train]\n",
    "y_valid = y_train[n_train:]\n",
    "y_train = y_train[:n_train]\n",
    "\n",
    "class Dummy:\n",
    "    pass\n",
    "env = Dummy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model(x, logits=False, training=False):\n",
    "    conv0 = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3],\n",
    "                             padding='same', name='conv0',\n",
    "                             activation=tf.nn.relu)\n",
    "    \n",
    "    pool0 = tf.layers.max_pooling2d(conv0, pool_size=[2, 2],\n",
    "                                    strides=2, name='pool0')\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(pool0, filters=64,\n",
    "                             kernel_size=[3, 3], padding='same',\n",
    "                             name='conv1', activation=tf.nn.relu)\n",
    "   \n",
    " \n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(conv1, pool_size=[2, 2],\n",
    "                                    strides=2, name='pool1')\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(pool1, filters=128,\n",
    "                             kernel_size=[1,1], padding='same',\n",
    "                             name='conv2', activation=tf.nn.relu)\n",
    "    \n",
    "\n",
    "    \n",
    "    flat = tf.reshape(conv2, [-1, 8*8*128], name='flatten')\n",
    "    \n",
    "    dense1 = tf.layers.dense(flat, units= 1024, activation=tf.nn.relu,\n",
    "                            name='dense1')\n",
    "    \n",
    "    dense2 = tf.layers.dense(dense1, units=128, activation=tf.nn.relu,\n",
    "                            name='dense2')\n",
    "    logits_ = tf.layers.dense(dense2, units=10, name='logits') #removed dropout\n",
    "    \n",
    "    y = tf.nn.softmax(logits_, name='ybar')\n",
    "    \n",
    "    if logits:\n",
    "        return y, logits_\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We need a scope since the inference graph will be reused later\n",
    "with tf.variable_scope('model'):\n",
    "    env.x = tf.placeholder(tf.float32, (None, img_rows, img_cols,\n",
    "                                        img_chas), name='x')\n",
    "    env.y = tf.placeholder(tf.float32, (None, n_classes), name='y')\n",
    "    env.training = tf.placeholder(bool, (), name='mode')\n",
    "\n",
    "    env.ybar, logits = model(env.x, logits=True,\n",
    "                             training=env.training)\n",
    "\n",
    "    z = tf.argmax(env.y, axis=1)\n",
    "    zbar = tf.argmax(env.ybar, axis=1)\n",
    "    env.count = tf.cast(tf.equal(z, zbar), tf.float32)\n",
    "    env.acc = tf.reduce_mean(env.count, name='acc')\n",
    "\n",
    "    xent = tf.nn.softmax_cross_entropy_with_logits(labels=env.y,\n",
    "                                                   logits=logits)\n",
    "    env.loss = tf.reduce_mean(xent, name='loss')\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    env.optim = tf.train.AdamOptimizer(beta1=0.9, beta2=0.999, epsilon=1e-08,).minimize(env.loss) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('model', reuse=True):\n",
    "    for i in range(n_classes):\n",
    "        if(i==0):\n",
    "            env.x_adv_wrt_class = (fgsm_wrt_class(model, env.x, i, step_size=.05, bbox_semi_side=10))\n",
    "        else:\n",
    "            x = (fgsm_wrt_class(model, env.x, i, step_size=.05, bbox_semi_side=10))\n",
    "            env.x_adv_wrt_class = tf.concat([env.x_adv_wrt_class, x],axis=0)\n",
    "    env.x_adv, env.all_flipped = fgsm(model, env.x, step_size=.05, bbox_semi_side=10) #epochs is redundant now!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0,
     4
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_model(label):\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess,  './models/cifar/' + label)\n",
    "    \n",
    "def restore_model(label):\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, './models/cifar/' + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0,
     23
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _evaluate(X_data, y_data, env):\n",
    "    print('\\nEvaluating')\n",
    "    n_sample = X_data.shape[0]\n",
    "    batch_size = 128\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    loss, acc = 0, 0\n",
    "    ns = 0\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        batch_loss, batch_count, batch_acc = sess.run(\n",
    "            [env.loss, env.count, env.acc],\n",
    "            feed_dict={env.x: X_data[start:end],\n",
    "                       env.y: y_data[start:end],\n",
    "                       env.training: False})\n",
    "        loss += batch_loss*batch_size\n",
    "        print('batch count: {0}'.format(np.sum(batch_count)))\n",
    "        ns+=batch_size\n",
    "        acc += batch_acc*batch_size\n",
    "    loss /= ns\n",
    "    acc /= ns\n",
    "#     print (ns)\n",
    "#     print (n_sample)\n",
    "    print(' loss: {0:.4f} acc: {1:.4f}'.format(loss, acc))\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0,
     15
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _predict(X_data, env):\n",
    "    print('\\nPredicting')\n",
    "    n_sample = X_data.shape[0]\n",
    "    batch_size = 128\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    yval = np.empty((X_data.shape[0], n_classes))\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        batch_y = sess.run(env.ybar, feed_dict={\n",
    "            env.x: X_data[start:end], env.training: False})\n",
    "        yval[start:end] = batch_y\n",
    "    return yval\n",
    "\n",
    "def train(label):\n",
    "    print('\\nTraining')\n",
    "    n_sample = X_train.shape[0]\n",
    "    batch_size = 128\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    n_epoch = 50\n",
    "    for epoch in range(n_epoch):\n",
    "        print('Epoch {0}/{1}'.format(epoch+1, n_epoch))\n",
    "        for ind in range(n_batch):\n",
    "            print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "            start = ind*batch_size\n",
    "            end = min(n_sample, start+batch_size)\n",
    "            sess.run(env.optim, feed_dict={env.x: X_train[start:end],\n",
    "                                           env.y: y_train[start:end],\n",
    "                                           env.training: True})\n",
    "        if(epoch%5 == 0):\n",
    "            model_label = label+ '{0}'.format(epoch)\n",
    "            print(\"saving model \" + model_label)\n",
    "            save_model(model_label)\n",
    "            \n",
    "    save_model(label)\n",
    "\n",
    "def train_again(X, y, epochs):\n",
    "    #Not making batches, do that if size > 128\n",
    "    for i in range(X.shape[0]):\n",
    "        print(i)\n",
    "        for e in range(epochs):\n",
    "            sess.run(env.optim, feed_dict={env.x: [X[i]],\n",
    "                                           env.y: [y[i]],\n",
    "                                           env.training: True})\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_adv_wrt_class(X, Y, label):\n",
    "    print('\\nCrafting adversarial')\n",
    "    n_sample = X.shape[0]\n",
    "    pred = np.argmax(Y,axis=1)\n",
    "    batch_size = 1\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    n_epoch = 20\n",
    "    x_adv_shape = list(X.shape)[1:]\n",
    "    x_adv_shape = np.append(np.append(n_sample,n_classes),x_adv_shape)\n",
    "    X_adv = np.empty(x_adv_shape)\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        tmp = sess.run(env.x_adv_wrt_class, feed_dict={env.x: X[start:end],\n",
    "                                             env.y: Y[start:end],\n",
    "                                             env.training: False})\n",
    "        tmp[pred[start]] = X[start]\n",
    "        X_adv[start:end] = tmp\n",
    "    print('\\n Not Saving Flipped')\n",
    "#     os.makedirs('data', exist_ok=True)\n",
    "#     save_as_txt(get_flip_path(label), X_adv)\n",
    "    return X_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_adv(X, Y, label):\n",
    "    print('\\nCrafting adversarial')\n",
    "    n_sample = X.shape[0]\n",
    "    batch_size = 1\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    n_epoch = 20\n",
    "    X_adv = np.empty_like(X)\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        tmp, all_flipped = sess.run([env.x_adv, env.all_flipped], feed_dict={env.x: X[start:end],\n",
    "                                             env.y: Y[start:end],\n",
    "                                             env.training: False})\n",
    "        X_adv[start:end] = tmp\n",
    "    print('\\nSaving adversarial')\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    save_as_txt(get_flip_path(label), X_adv)\n",
    "    return X_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_compare(flip,flip_overfit, n, i):\n",
    "    %matplotlib inline\n",
    "    t = np.arange(0,n,1)\n",
    "    plt.xticks(t)\n",
    "    plt.plot(t, flip[:n], 'r--', t, flip_overfitflip_overfit[:n],'b--')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='After overfitting')\n",
    "    red_patch = mpatches.Patch(color='red', label='Before overfitting')\n",
    "    plt.legend(handles=[blue_patch, red_patch])\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "    plt.title(\"From Class \" + str(i))\n",
    "    plt.show()\n",
    "\n",
    "def compare_both_models(X,y, X_flip, X_flip_overfit):\n",
    "    \n",
    "    for cls in range(n_classes):\n",
    "        class_indices = get_class_indices(X,cls)\n",
    "        l2_flip = find_l2_batch(X[class_indices], X_flip[class_indices])\n",
    "        l2_flip_overfit = find_l2_batch(X[class_indices], X_flip_overfit[class_indices])\n",
    "        for i in range(l2_flip.shape[0]):\n",
    "            plot_compare(l2_flip[i],l2_flip_overfit[i],n_classes,cls)      \n",
    "        \n",
    "def main_func():\n",
    "    method = 2\n",
    "    n = 100\n",
    "    epochs = 100\n",
    "    label=\"cifar_with_cnn\"\n",
    "    train_again_epochs = 100\n",
    "    n_train_again = 100\n",
    "    # train(label)\n",
    "    restore_model(label + str(epochs))\n",
    "    # _evaluate(X_train, y_train, env)\n",
    "    \n",
    "    X = X_train[:n_train_again]\n",
    "    y = y_train[:n_train_again]\n",
    "    \n",
    "    train_label = make_label(\"train\", method, epochs,n, False)\n",
    "    X_flip=  create_adv_wrt_class(X, y, label)\n",
    "\n",
    "    train_again(X, y, train_again_epochs)\n",
    "    X_flip_overfit = create_adv_wrt_class(X, y, label)\n",
    "    compare_both_models(X,y, X_flip, X_flip_overfit)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/cifar/cifar_with_cnn100\n",
      "\n",
      "Crafting adversarial\n",
      " batch 1/100\r"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [1,32,32,3] vs. [1,3072]\n\t [[Node: model_1/fgsm_1/mul_1 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](model_1/fgsm_1/mul, model_1/fgsm_1/Reshape_3)]]\n\nCaused by op 'model_1/fgsm_1/mul_1', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-70c4e8f953e7>\", line 6, in <module>\n    x = (fgsm_wrt_class(model, env.x, i, step_size=.05, bbox_semi_side=10))\n  File \"/home/yash/Desktop/Decision-Flip-Experiments/fgsm_cifar_wrt_class.py\", line 79, in fgsm_wrt_class\n    name='fgsm')\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2816, in while_loop\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2640, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2590, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/home/yash/Desktop/Decision-Flip-Experiments/fgsm_cifar_wrt_class.py\", line 69, in _body\n    dy_dx = ans*dy_dx\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 894, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 1117, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 2726, in _mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [1,32,32,3] vs. [1,3072]\n\t [[Node: model_1/fgsm_1/mul_1 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](model_1/fgsm_1/mul, model_1/fgsm_1/Reshape_3)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [1,32,32,3] vs. [1,3072]\n\t [[Node: model_1/fgsm_1/mul_1 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](model_1/fgsm_1/mul, model_1/fgsm_1/Reshape_3)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6bf2be90a1e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-7781fdad5fd4>\u001b[0m in \u001b[0;36mmain_func\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mtrain_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mX_flip\u001b[0m\u001b[0;34m=\u001b[0m  \u001b[0mcreate_adv_wrt_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mtrain_again\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_again_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-29602c6e9fcc>\u001b[0m in \u001b[0;36mcreate_adv_wrt_class\u001b[0;34m(X, Y, label)\u001b[0m\n\u001b[1;32m     15\u001b[0m         tmp = sess.run(env.x_adv_wrt_class, feed_dict={env.x: X[start:end],\n\u001b[1;32m     16\u001b[0m                                              \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                                              env.training: False})\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mX_adv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [1,32,32,3] vs. [1,3072]\n\t [[Node: model_1/fgsm_1/mul_1 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](model_1/fgsm_1/mul, model_1/fgsm_1/Reshape_3)]]\n\nCaused by op 'model_1/fgsm_1/mul_1', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-70c4e8f953e7>\", line 6, in <module>\n    x = (fgsm_wrt_class(model, env.x, i, step_size=.05, bbox_semi_side=10))\n  File \"/home/yash/Desktop/Decision-Flip-Experiments/fgsm_cifar_wrt_class.py\", line 79, in fgsm_wrt_class\n    name='fgsm')\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2816, in while_loop\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2640, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2590, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/home/yash/Desktop/Decision-Flip-Experiments/fgsm_cifar_wrt_class.py\", line 69, in _body\n    dy_dx = ans*dy_dx\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 894, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 1117, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 2726, in _mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [1,32,32,3] vs. [1,3072]\n\t [[Node: model_1/fgsm_1/mul_1 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](model_1/fgsm_1/mul, model_1/fgsm_1/Reshape_3)]]\n"
     ]
    }
   ],
   "source": [
    "main_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
